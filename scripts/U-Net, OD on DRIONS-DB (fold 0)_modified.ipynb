{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of modified U-Net for Optic Disc on DRIONS-DB database, 256 px images (cross-validation fold #0).\n",
    "\n",
    "You can either train your model or upload a pre-trained one from:\n",
    "*../models_weights/05.03,02:40,U-Net light, on DRIONS-DB 256 px fold 0, SGD, high augm, CLAHE, log_dice loss/last_checkpoint.hdf5*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not import submodules (exact error was: DLL load failed: The specified module could not be found.).\n",
      "\n",
      "There are many reasons for this error the most common one is that you have\n",
      "either not built the packages or have built (using `python setup.py build`) or\n",
      "installed them (using `python setup.py install`) and then proceeded to test\n",
      "mahotas **without changing the current directory**.\n",
      "\n",
      "Try installing and then changing to another directory before importing mahotas.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "#import warnings\n",
    "#warnings.simplefilter('ignore')\n",
    "import scipy as sp\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import skimage\n",
    "import skimage.exposure\n",
    "import mahotas as mh\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "from tqdm import tqdm_notebook\n",
    "from IPython.display import display\n",
    "from dual_IDG import DualImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, \\\n",
    "    Conv2D, MaxPooling2D, ZeroPadding2D, Input, Embedding, \\\n",
    "    Lambda, UpSampling2D, Cropping2D, Concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, CSVLogger\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.3.1\n",
      "TensorFlow version: 1.14.0\n"
     ]
    }
   ],
   "source": [
    "print('Keras version:', keras.__version__)\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_IOU_gpu(X, Y):\n",
    "    \"\"\"Computes mean Intersection-over-Union (IOU) for two arrays of binary images.\n",
    "    Assuming X and Y are of shape (n_images, w, h).\"\"\"\n",
    "    \n",
    "    #X_fl = K.clip(K.batch_flatten(X), K.epsilon(), 1.)\n",
    "    #Y_fl = K.clip(K.batch_flatten(Y), K.epsilon(), 1.)\n",
    "    X_fl = K.clip(K.batch_flatten(X), 0., 1.)\n",
    "    Y_fl = K.clip(K.batch_flatten(Y), 0., 1.)\n",
    "    X_fl = K.cast(K.greater(X_fl, 0.5), 'float32')\n",
    "    Y_fl = K.cast(K.greater(Y_fl, 0.5), 'float32')\n",
    "\n",
    "    intersection = K.sum(X_fl * Y_fl, axis=1)\n",
    "    union = K.sum(K.maximum(X_fl, Y_fl), axis=1)\n",
    "    # if union == 0, it follows that intersection == 0 => score should be 0.\n",
    "    union = K.switch(K.equal(union, 0), K.ones_like(union), union)\n",
    "    return K.mean(intersection / K.cast(union, 'float32'))\n",
    "\n",
    "\n",
    "def mean_IOU_gpu_loss(X, Y):\n",
    "    return -mean_IOU_gpu(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_true, y_pred):\n",
    "    # Workaround for shape bug. For some reason y_true shape was not being set correctly\n",
    "    #y_true.set_shape(y_pred.get_shape())\n",
    "\n",
    "    # Without K.clip, K.sum() behaves differently when compared to np.count_nonzero()\n",
    "    #y_true_f = K.clip(K.batch_flatten(y_true), K.epsilon(), 1.)\n",
    "    #y_pred_f = K.clip(K.batch_flatten(y_pred), K.epsilon(), 1.)\n",
    "    y_true_f = K.clip(K.batch_flatten(y_true), 0., 1.)\n",
    "    y_pred_f = K.clip(K.batch_flatten(y_pred), 0., 1.)\n",
    "    #y_pred_f = K.greater(y_pred_f, 0.5)\n",
    "\n",
    "    intersection = 2 * K.sum(y_true_f * y_pred_f, axis=1)\n",
    "    union = K.sum(y_true_f * y_true_f, axis=1) + K.sum(y_pred_f * y_pred_f, axis=1)\n",
    "    return K.mean(intersection / union)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return -dice(y_true, y_pred)\n",
    "\n",
    "\n",
    "def log_dice_loss(y_true, y_pred):\n",
    "    return -K.log(dice(y_true, y_pred))\n",
    "\n",
    "\n",
    "def dice_metric(y_true, y_pred):\n",
    "    \"\"\"An exact Dice score for binary tensors.\"\"\"\n",
    "    y_true_f = K.cast(K.greater(y_true, 0.5), 'float32')\n",
    "    y_pred_f = K.cast(K.greater(y_pred, 0.5), 'float32')\n",
    "    return dice(y_true_f, y_pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_to_th_encoding(X):\n",
    "    return np.rollaxis(X, 3, 1)\n",
    "\n",
    "\n",
    "def th_to_tf_encoding(X):\n",
    "    return np.rollaxis(X, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5f = h5py.File(os.path.join(os.path.dirname(os.getcwd()), 'data', 'hdf5_datasets', 'all_data.hdf5'), 'r')\n",
    "h5f = h5py.File(os.path.join(os.path.dirname(os.getcwd()), 'data', 'hdf5_datasets', 'DRIONS_DB.hdf5'), 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net architecture\n",
    "\n",
    "<img src=\"../pics/u_net_arch.png\" width=80%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layer import *\n",
    "from keras.optimizers import *\n",
    "from keras.models import *\n",
    "from attention_module import *\n",
    "\n",
    "def get_unet_light(img_rows=256, img_cols=256):\n",
    "    inputs = Input((3, img_rows, img_cols))\n",
    "\n",
    "    # contract path\n",
    "    conv1 = Conv2D(32, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Dropout(0.3)(conv1)\n",
    "    conv1 = Conv2D(32, kernel_size=3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Dropout(0.3)(conv2)\n",
    "    conv2 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Dropout(0.3)(conv3)\n",
    "    conv3 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Dropout(0.3)(conv4)\n",
    "    conv4 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    # bottom\n",
    "    conv5 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Dropout(0.3)(conv5)\n",
    "    conv5 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # expansive path\n",
    "    up6 = Concatenate(axis=1)([UpSampling2D(size=(2, 2))(conv5), conv4])\n",
    "    conv6 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(up6)\n",
    "    conv6 = Dropout(0.3)(conv6)\n",
    "    conv6 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = Concatenate(axis=1)([UpSampling2D(size=(2, 2))(conv6), conv3])\n",
    "    conv7 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(up7)\n",
    "    conv7 = Dropout(0.3)(conv7)\n",
    "    conv7 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = Concatenate(axis=1)([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
    "    conv8 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(up8)\n",
    "    conv8 = Dropout(0.3)(conv8)\n",
    "    conv8 = Conv2D(64, kernel_size=3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = Concatenate(axis=1)([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
    "    conv9 = Conv2D(32, kernel_size=3, activation='relu', padding='same')(up9)\n",
    "    conv9 = Dropout(0.3)(conv9)\n",
    "    conv9 = Conv2D(32, kernel_size=3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, kernel_size=1, activation='sigmoid', padding='same')(conv9)\n",
    "    #conv10 = Flatten()(conv10)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.get_shape() 00: (?, 256, 256, 3)\n",
      "x.get_shape() 0: (?, 32, 256, 3)\n",
      "x.get_shape() 00: (?, 32, 256, 3)\n",
      "x.get_shape() 0: (?, 32, 256, 3)\n",
      "blockInput.get_shape() : (?, 256, 256, 3)\n",
      "x.get_shape() : (?, 32, 256, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Operands could not be broadcast together with shapes (32, 256, 3) (256, 256, 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-22-1a96b2bbc52b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mattention_module\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mCARUNet_modified\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCARUNet_modified\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m256\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m256\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m model.compile(optimizer=SGD(lr=3e-4, momentum=0.95),\n\u001B[0;32m      9\u001B[0m               \u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlog_dice_loss\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Program Files\\PyCharmProjects\\optic-nerve-cnn\\scripts\\CARUNet_modified.py\u001B[0m in \u001B[0;36mCARUNet_modified\u001B[1;34m(input_size, start_neurons, keep_prob, block_size)\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[1;31m# print(inputs.shape())\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[1;31m# contract path\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m     \u001B[0mconv1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresidual_drop_block\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstart_neurons\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mblock_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mblock_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkeep_prob\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkeep_prob\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m     \u001B[0mconv1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRCAB\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconv1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkeep_prob\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mkeep_prob\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mblock_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mblock_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m     \u001B[0mpool1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMaxPooling2D\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconv1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Program Files\\PyCharmProjects\\optic-nerve-cnn\\scripts\\layer.py\u001B[0m in \u001B[0;36mresidual_drop_block\u001B[1;34m(blockInput, num_filters, batch_activate, keep_prob, block_size)\u001B[0m\n\u001B[0;32m     34\u001B[0m         \u001B[0mblockInput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mConv2D\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum_filters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpadding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"same\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mblockInput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 36\u001B[1;33m     \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mAdd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mblockInput\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     37\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mbatch_activate\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBatchActivate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs, **kwargs)\u001B[0m\n\u001B[0;32m    461\u001B[0m                                          \u001B[1;34m'You can build it manually via: '\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    462\u001B[0m                                          '`layer.build(batch_input_shape)`')\n\u001B[1;32m--> 463\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0munpack_singleton\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_shapes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    464\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuilt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    465\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\layers\\merge.py\u001B[0m in \u001B[0;36mbuild\u001B[1;34m(self, input_shape)\u001B[0m\n\u001B[0;32m     89\u001B[0m                 \u001B[0mshape\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minput_shape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m             output_shape = self._compute_elemwise_op_output_shape(output_shape,\n\u001B[1;32m---> 91\u001B[1;33m                                                                   shape)\n\u001B[0m\u001B[0;32m     92\u001B[0m         \u001B[1;31m# If the inputs have different ranks, we have to reshape them\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m         \u001B[1;31m# to make them broadcastable.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\layers\\merge.py\u001B[0m in \u001B[0;36m_compute_elemwise_op_output_shape\u001B[1;34m(self, shape1, shape2)\u001B[0m\n\u001B[0;32m     59\u001B[0m                     raise ValueError('Operands could not be broadcast '\n\u001B[0;32m     60\u001B[0m                                      \u001B[1;34m'together with shapes '\u001B[0m \u001B[1;33m+\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m                                      str(shape1) + ' ' + str(shape2))\n\u001B[0m\u001B[0;32m     62\u001B[0m                 \u001B[0moutput_shape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput_shape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Operands could not be broadcast together with shapes (32, 256, 3) (256, 256, 3)"
     ]
    }
   ],
   "source": [
    "from layer import *\n",
    "from keras.optimizers import *\n",
    "from keras.models import *\n",
    "from attention_module import *\n",
    "from CARUNet_modified import *\n",
    "model = CARUNet_modified(input_size=(256, 256, 3))\n",
    "model.compile(optimizer=SGD(lr=3e-4, momentum=0.95),\n",
    "              loss=log_dice_loss,\n",
    "              metrics=[mean_IOU_gpu, dice_metric])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DRIONS-DB\n",
    "\n",
    "Accessing data, preparing train/validation sets division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = h5f['DRIONS-DB/256 px/images']\n",
    "Y = h5f['DRIONS-DB/256 px/disc']\n",
    "X = np.reshape(X, (len(X), 256, 256, 3))  # adapt this if using `channels_first` image data format\n",
    "X = np.reshape(X, (len(X), 256, 256, 1))  # adapt this if using `channels_first` im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx_cv, test_idx_cv = [], []\n",
    "\n",
    "for _train_idx, _test_idx in KFold(n_splits=5, random_state=1).split(X):\n",
    "    print(_train_idx, _test_idx)\n",
    "    train_idx_cv.append(_train_idx)\n",
    "    test_idx_cv.append(_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_idx = h5f['RIM-ONE v3/train_idx_driu']\n",
    "#test_idx = h5f['RIM-ONE v3/test_idx_driu']\n",
    "\n",
    "train_idx = train_idx_cv[0]\n",
    "test_idx = test_idx_cv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(train_idx), len(test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator of augmented data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idg = DualImageDataGenerator(#rescale=1/255.0,\n",
    "                                   #samplewise_center=True, samplewise_std_normalization=True,\n",
    "                                   horizontal_flip=True, vertical_flip=True,\n",
    "                                   rotation_range=50, width_shift_range=0.15, height_shift_range=0.15,\n",
    "                                   zoom_range=(0.7, 1.3),\n",
    "                                   fill_mode='constant', cval=0.0)\n",
    "test_idg = DualImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing function and data generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch_X, batch_y, train_or_test='train'):\n",
    "    batch_X = batch_X / 255.0\n",
    "    batch_y = batch_y / 255.0\n",
    "    if train_or_test == 'train':\n",
    "        batch_X, batch_y = next(train_idg.flow(batch_X, batch_y, batch_size=len(batch_X), shuffle=False))\n",
    "    elif train_or_test == 'test':\n",
    "        batch_X, batch_y = next(test_idg.flow(batch_X, batch_y, batch_size=len(batch_X), shuffle=False))\n",
    "    batch_X = th_to_tf_encoding(batch_X)\n",
    "    batch_X = [skimage.exposure.equalize_adapthist(batch_X[i]) \n",
    "               for i in range(len(batch_X))]\n",
    "    batch_X = np.array(batch_X)\n",
    "    batch_X = tf_to_th_encoding(batch_X)\n",
    "    return batch_X, batch_y\n",
    "\n",
    "\n",
    "def data_generator(X, y, train_or_test='train', batch_size=3, return_orig=False, stationary=False):\n",
    "    while True:\n",
    "        if train_or_test == 'train':\n",
    "            idx = np.random.choice(train_idx, size=batch_size)\n",
    "        elif train_or_test == 'test':\n",
    "            if stationary:\n",
    "                idx = test_idx[:batch_size]\n",
    "            else:\n",
    "                idx = np.random.choice(test_idx, size=batch_size)\n",
    "        batch_X = [X[i] for i in idx]\n",
    "        batch_X = np.array(batch_X).copy()\n",
    "        batch_y = [y[i] for i in idx]\n",
    "        batch_y = np.array(batch_y).copy()\n",
    "        batch_X = tf_to_th_encoding(batch_X)\n",
    "        batch_y = tf_to_th_encoding(batch_y)\n",
    "        if return_orig:\n",
    "            batch_X_orig, batch_Y_orig = batch_X.copy(), batch_y.copy()\n",
    "        \n",
    "        batch_X, batch_y = preprocess(batch_X, batch_y, train_or_test)\n",
    "        \n",
    "        if not return_orig:\n",
    "            yield batch_X, batch_y\n",
    "        else:\n",
    "            yield batch_X, batch_y, batch_X_orig, batch_Y_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the data generator and generator for augmented data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen = data_generator(X, Y, 'train', batch_size=1)\n",
    "batch = next(gen)\n",
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.imshow(np.rollaxis(batch[0][0], 0, 3))\n",
    "#plt.colorbar(mappable=fig)\n",
    "plt.show()\n",
    "plt.imshow(batch[1][0][0], cmap=plt.cm.Greys_r); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_name = \"U-Net light, on DRIONS-DB 256 px fold 0, SGD, high augm, CLAHE, log_dice loss\"\n",
    "weights_folder = os.path.join(os.path.dirname(os.getcwd()), 'models_weights',\n",
    "                              '{},{}'.format(datetime.now().strftime('%d.%m,%H:%M'), arch_name))\n",
    "print(weights_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    return folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, Y_valid = next(data_generator(X, Y, train_or_test='test', batch_size=100, stationary=True))\n",
    "plt.imshow(np.rollaxis(X_valid[0], 0, 3)); plt.show()\n",
    "print(X_valid.shape, Y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "If a pretrained model needs to be used, first run \"Loading model\" section below and then go the \"Comprehensive visual check\", skipping this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(data_generator(X, Y, train_or_test='train', batch_size=1), \n",
    "                              steps_per_epoch=99,\n",
    "                              max_queue_size=1,\n",
    "                              \n",
    "                              validation_data=(X_valid, Y_valid),\n",
    "                              #validation_data=data_generator(X, Y, train_or_test='test', batch_size=1),\n",
    "                              #nb_val_samples=100,\n",
    "                              \n",
    "                              epochs=500, verbose=1,\n",
    "                              \n",
    "                              callbacks=[CSVLogger(os.path.join(folder(weights_folder), 'training_log.csv')),\n",
    "                                         #ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.5, verbose=1, patience=40),\n",
    "                                         ModelCheckpoint(os.path.join(folder(weights_folder),\n",
    "                                               #'weights.ep-{epoch:02d}-val_mean_IOU-{val_mean_IOU_gpu:.2f}_val_loss_{val_loss:.2f}.hdf5',\n",
    "                                               'last_checkpoint.hdf5'),\n",
    "                                               monitor='val_loss', mode='min', save_best_only=True, \n",
    "                                               save_weights_only=False, verbose=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_iou, pred_dice = [], []\n",
    "\n",
    "for i, img_no in enumerate(test_idx):\n",
    "    print('image #{}'.format(img_no))\n",
    "    img = X[img_no]\n",
    "    batch_X = X_valid[i:i + 1]\n",
    "    batch_y = Y_valid[i:i + 1]\n",
    "    \n",
    "    pred = (model.predict(batch_X)[0, 0] > 0.5).astype(np.float64)\n",
    "    #corr = Y[img_no][..., 0]\n",
    "    corr = th_to_tf_encoding(batch_y)[0, ..., 0]\n",
    "    \n",
    "    # mean filtering:\n",
    "    #pred = mh.mean_filter(pred, Bc=mh.disk(10)) > 0.5\n",
    "    \n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax = fig.add_subplot(1, 3, 1)\n",
    "    ax.imshow(pred, cmap=plt.cm.Greys_r)\n",
    "    ax.set_title('Predicted')\n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    ax.imshow(corr, cmap=plt.cm.Greys_r)\n",
    "    ax.set_title('Correct')\n",
    "    ax = fig.add_subplot(1, 3, 3)\n",
    "    #ax.imshow(img)\n",
    "    ax.imshow(th_to_tf_encoding(batch_X)[0])\n",
    "    ax.set_title('Image')\n",
    "    plt.show()\n",
    "    \n",
    "    cur_iou = K.eval(mean_IOU_gpu(pred[None, None, ...], corr[None, None, ...]))\n",
    "    cur_dice = K.eval(dice(pred[None, None, ...], corr[None, None, ...]))\n",
    "    print('IOU: {}\\nDice: {}'.format(cur_iou, cur_dice))\n",
    "    pred_iou.append(cur_iou)\n",
    "    pred_dice.append(cur_dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquiring scores for the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(pred_iou))\n",
    "print(np.mean(pred_dice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the best and the worst cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img_pred_corr(i, file_suffix):    # i is index of image in test_idx\n",
    "    img_no = test_idx[i]\n",
    "    batch_X = X[img_no:img_no + 1]\n",
    "    batch_X = tf_to_th_encoding(batch_X)\n",
    "    batch_y = Y[img_no:img_no + 1]\n",
    "    batch_y = tf_to_th_encoding(batch_y)\n",
    "    batch_X, batch_y = preprocess(batch_X, batch_y, 'test')\n",
    "    \n",
    "    pred = model.predict(batch_X)[0, 0] > 0.5\n",
    "    #corr = Y[img_no][..., 0]\n",
    "    corr = th_to_tf_encoding(batch_y)[0, ..., 0]\n",
    "    \n",
    "    fig = plt.figure(figsize=(9, 4))\n",
    "    ax = fig.add_subplot(1, 3, 1)\n",
    "    ax.imshow(pred, cmap=plt.cm.Greys_r)\n",
    "    ax.set_title('Predicted')\n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    ax.imshow(corr, cmap=plt.cm.Greys_r)\n",
    "    ax.set_title('Correct')\n",
    "    ax = fig.add_subplot(1, 3, 3)\n",
    "    #ax.imshow(img)\n",
    "    ax.imshow(X[img_no])\n",
    "    ax.set_title('Image')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imsave('drions_db_fold_0_{}_case_image.png'.format(file_suffix), X[img_no])\n",
    "    plt.imsave('drions_db_fold_0_{}_case_pred.png'.format(file_suffix), pred, cmap=plt.cm.Greys_r)\n",
    "    plt.imsave('drions_db_fold_0_{}_case_corr.png'.format(file_suffix), corr, cmap=plt.cm.Greys_r)\n",
    "\n",
    "\n",
    "best_idx = np.argmax(pred_iou)\n",
    "worst_idx = np.argmin(pred_iou)\n",
    "show_img_pred_corr(best_idx, 'best')\n",
    "print('IOU: {} (best)'.format(pred_iou[best_idx]))\n",
    "show_img_pred_corr(worst_idx, 'worst')\n",
    "print('IOU: {} (worst)'.format(pred_iou[worst_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_model = True   # lock\n",
    "if not load_model:\n",
    "    print('load_model == False')\n",
    "else:\n",
    "    # specify file:\n",
    "    #model_path = '../models_weights/01.11,22:38,U-Net on DRIONS-DB 256 px, Adam, augm, log_dice loss/' \\\n",
    "    #    'weights.ep-20-val_mean_IOU-0.81_val_loss_0.08.hdf5'\n",
    "    \n",
    "    # or get the most recently modified file in a folder:\n",
    "    model_folder = os.path.join(os.path.dirname(os.getcwd()), 'models_weights', '05.03,02_40,U-Net light, on DRIONS-DB 256 px fold 0, SGD, high augm, CLAHE, log_dice loss')\n",
    "    \n",
    "    model_path = max(glob.glob(os.path.join(model_folder, '*.hdf5')), key=os.path.getctime)\n",
    "    if load_model and not os.path.exists(model_path):\n",
    "        raise Exception('`model_path` does not exist')\n",
    "    print('Loading weights from', model_path)\n",
    "\n",
    "    if load_model:\n",
    "        #with open(model_path + ' arch.json') as arch_file:\n",
    "        #    json_string = arch_file.read()\n",
    "        #new_model = model_from_json(json_string)\n",
    "        model.load_weights(model_path)\n",
    "    \n",
    "    # Reading log statistics\n",
    "    import pandas as pd\n",
    "    \n",
    "    log_path = os.path.join(model_folder, 'training_log.csv')\n",
    "    if os.path.exists(log_path):\n",
    "        log = pd.read_csv(log_path)\n",
    "        if log['epoch'].dtype != 'int64':\n",
    "            log = log.loc[log.epoch != 'epoch']\n",
    "        print('\\nmax val mean IOU: {}, at row:'.format(log['val_mean_IOU_gpu'].max()))\n",
    "        print(log.loc[log['val_mean_IOU_gpu'].idxmax()])\n",
    "        if 'val_dice_metric' in log.columns:\n",
    "            print('\\n' + 'max val dice_metric: {}, at row:'.format(log['val_dice_metric'].max()))\n",
    "            print(log.loc[log['val_dice_metric'].idxmax()])\n",
    "        if 'val_dice' in log.columns:\n",
    "            print('\\n' + 'max val dice: {}, at row:'.format(log['val_dice'].max()))\n",
    "            print(log.loc[log['val_dice'].idxmax()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}